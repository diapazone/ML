{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c-iqEAkeFCRR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Вспомогательные ячейки"
      ],
      "metadata": {
        "id": "P-MbUhhXFJsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88NrayHpV4Ay",
        "outputId": "907c7b88-5a9e-4958-f0ea-cb430fcfe8f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XAzpisQttNjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0d1d5f-e6dd-4320-bfc3-d22b69dee08f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.losses import metric_learning\n",
        "from tensorflow_addons.utils.keras_utils import LossFunctionWrapper\n",
        "from tensorflow_addons.utils.types import FloatTensorLike, TensorLike\n",
        "from typeguard import typechecked\n",
        "from typing import Optional, Union, Callable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _masked_maximum(data, mask, dim=1):\n",
        "    \"\"\"Computes the axis wise maximum over chosen elements.\n",
        "\n",
        "    Args:\n",
        "      data: 2-D float `Tensor` of size [n, m].\n",
        "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
        "      dim: The dimension over which to compute the maximum.\n",
        "\n",
        "    Returns:\n",
        "      masked_maximums: N-D `Tensor`.\n",
        "        The maximized dimension is of size 1 after the operation.\n",
        "    \"\"\"\n",
        "    axis_minimums = tf.math.reduce_min(data, dim, keepdims=True)\n",
        "    masked_maximums = (\n",
        "        tf.math.reduce_max(\n",
        "            tf.math.multiply(data - axis_minimums, mask), dim, keepdims=True\n",
        "        )\n",
        "        + axis_minimums\n",
        "    )\n",
        "    return masked_maximums\n",
        "\n",
        "\n",
        "def _masked_minimum(data, mask, dim=1):\n",
        "    \"\"\"Computes the axis wise minimum over chosen elements.\n",
        "\n",
        "    Args:\n",
        "      data: 2-D float `Tensor` of size [n, m].\n",
        "      mask: 2-D Boolean `Tensor` of size [n, m].\n",
        "      dim: The dimension over which to compute the minimum.\n",
        "\n",
        "    Returns:\n",
        "      masked_minimums: N-D `Tensor`.\n",
        "        The minimized dimension is of size 1 after the operation.\n",
        "    \"\"\"\n",
        "    axis_maximums = tf.math.reduce_max(data, dim, keepdims=True)\n",
        "    masked_minimums = (\n",
        "        tf.math.reduce_min(\n",
        "            tf.math.multiply(data - axis_maximums, mask), dim, keepdims=True\n",
        "        )\n",
        "        + axis_maximums\n",
        "    )\n",
        "    return masked_minimums"
      ],
      "metadata": {
        "id": "zJy5s6ratPDK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Код исходной функции"
      ],
      "metadata": {
        "id": "EyJiXef9FnpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.utils.register_keras_serializable(package=\"Addons\")\n",
        "@tf.function\n",
        "def triplet_semihard_loss(\n",
        "    y_true: TensorLike,\n",
        "    y_pred: TensorLike,\n",
        "    margin: FloatTensorLike = 1.0,\n",
        "    distance_metric: Union[str, Callable] = \"L2\",\n",
        ") -> tf.Tensor:\n",
        "\n",
        "    labels, embeddings = y_true, y_pred\n",
        "\n",
        "    convert_to_float32 = (\n",
        "        embeddings.dtype == tf.dtypes.float16 or embeddings.dtype == tf.dtypes.bfloat16\n",
        "    )\n",
        "    precise_embeddings = (\n",
        "        tf.cast(embeddings, tf.dtypes.float32) if convert_to_float32 else embeddings\n",
        "    )\n",
        "\n",
        "    # Reshape label tensor to [batch_size, 1].\n",
        "    lshape = tf.shape(labels)\n",
        "    labels = tf.reshape(labels, [lshape[0], 1])\n",
        "    # Build pairwise squared distance matrix\n",
        "\n",
        "    if distance_metric == \"L2\":\n",
        "        pdist_matrix = metric_learning.pairwise_distance(\n",
        "            precise_embeddings, squared=False\n",
        "        )\n",
        "\n",
        "    elif distance_metric == \"squared-L2\":\n",
        "        pdist_matrix = metric_learning.pairwise_distance(\n",
        "            precise_embeddings, squared=True\n",
        "        )\n",
        "\n",
        "    elif distance_metric == \"angular\":\n",
        "        pdist_matrix = metric_learning.angular_distance(precise_embeddings)\n",
        "\n",
        "    else:\n",
        "        pdist_matrix = distance_metric(precise_embeddings)\n",
        "\n",
        "\n",
        "    # Build pairwise binary adjacency matrix.\n",
        "    adjacency = tf.math.equal(labels, tf.transpose(labels))\n",
        "    # Invert so we can select negatives only.\n",
        "    adjacency_not = tf.math.logical_not(adjacency)\n",
        "\n",
        "    batch_size = tf.size(labels)\n",
        "\n",
        "    # Compute the mask.\n",
        "    pdist_matrix_tile = tf.tile(pdist_matrix, [batch_size, 1])\n",
        "    mask = tf.math.logical_and(\n",
        "        tf.tile(adjacency_not, [batch_size, 1]),\n",
        "        tf.math.greater(\n",
        "            pdist_matrix_tile, tf.reshape(tf.transpose(pdist_matrix), [-1, 1])\n",
        "        ),\n",
        "    )\n",
        "    mask_final = tf.reshape(\n",
        "        tf.math.greater(\n",
        "            tf.math.reduce_sum(\n",
        "                tf.cast(mask, dtype=tf.dtypes.float32), 1, keepdims=True\n",
        "            ),\n",
        "            0.0,\n",
        "        ),\n",
        "        [batch_size, batch_size],\n",
        "    )\n",
        "    mask_final = tf.transpose(mask_final)\n",
        "\n",
        "    adjacency_not = tf.cast(adjacency_not, dtype=tf.dtypes.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.dtypes.float32)\n",
        "\n",
        "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
        "    negatives_outside = tf.reshape(\n",
        "        _masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size]\n",
        "    )\n",
        "    negatives_outside = tf.transpose(negatives_outside)\n",
        "\n",
        "    # negatives_inside: largest D_an.\n",
        "    negatives_inside = tf.tile(\n",
        "        _masked_maximum(pdist_matrix, adjacency_not), [1, batch_size]\n",
        "    )\n",
        "    semi_hard_negatives = tf.where(mask_final, negatives_outside, negatives_inside)\n",
        "\n",
        "    loss_mat = tf.math.add(margin, pdist_matrix - semi_hard_negatives)\n",
        "\n",
        "    mask_positives = tf.cast(adjacency, dtype=tf.dtypes.float32) - tf.linalg.diag(\n",
        "        tf.ones([batch_size])\n",
        "    )\n",
        "\n",
        "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
        "    #   in semihard, they take all positive pairs except the diagonal.\n",
        "    num_positives = tf.math.reduce_sum(mask_positives)\n",
        "\n",
        "    triplet_loss = tf.math.truediv(\n",
        "        tf.math.reduce_sum(\n",
        "            tf.math.maximum(tf.math.multiply(loss_mat, mask_positives), 0.0)\n",
        "        ),\n",
        "        num_positives,\n",
        "    )\n",
        "\n",
        "    if convert_to_float32:\n",
        "        return tf.cast(triplet_loss, embeddings.dtype)\n",
        "    else:\n",
        "        return triplet_loss"
      ],
      "metadata": {
        "id": "wvpfwzGCtUoT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Код multilabel функции"
      ],
      "metadata": {
        "id": "dQaWU1FeVNjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multilabel_triplet_semihard_loss(y_true, y_pred):\n",
        "  count_obj = len(y_true) # кол-во экземпляров\n",
        "  count_labels = len(y_true[0]) # кол-во меток у экземпляра\n",
        "\n",
        "  #определяем якорь и позитивный экземпляр\n",
        "  anchor = None\n",
        "  positive = None\n",
        "  i_know_who_is_who = False\n",
        "  for i in range(count_obj):\n",
        "    for j in range(count_obj):\n",
        "      if i != j and tf.reduce_all(tf.equal(y_true[i], y_true[j])):\n",
        "        anchor = y_true[i]\n",
        "        positive = y_true[j]\n",
        "        i_know_who_is_who = True\n",
        "        break\n",
        "    if i_know_who_is_who:\n",
        "      break\n",
        "\n",
        "  #определяем количество совпадающих меток\n",
        "  same_labels = []\n",
        "  for obj in y_true:\n",
        "    if not tf.reduce_all(tf.equal(obj, anchor)):\n",
        "      same_labels.append(0)\n",
        "      for label in obj:\n",
        "        if label in anchor:\n",
        "          same_labels[len(same_labels)-1] += 1\n",
        "  #усредняем количество совпадающих меток\n",
        "  count_same_labels = sum(same_labels) / len(same_labels)\n",
        "\n",
        "  #определяем коэффициент ошибки\n",
        "  cf = (count_labels - count_same_labels)/count_labels\n",
        "\n",
        "  #считаем ошибку\n",
        "  result = 0\n",
        "  y_true = np.transpose(y_true)\n",
        "  for t in y_true:\n",
        "    result += triplet_semihard_loss(t, y_pred)\n",
        "  return result*cf"
      ],
      "metadata": {
        "id": "hIODhAmPRPoo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестирование"
      ],
      "metadata": {
        "id": "oIlBfUf_dgEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.constant([[0.5, 0.], [0.5, 0.], [0.5, 0.], [0.5, 0.]], dtype=tf.float32)\n",
        "\n",
        "#negative частично совпадает с anchor\n",
        "#результат должен быть поменьше\n",
        "y_true = tf.constant([[1, 1], [1, 1], [1, 2], [1, 0]], dtype=tf.float32)\n",
        "print(multilabel_triplet_semihard_loss(y_true, y_pred))\n",
        "\n",
        "# negative полностью отличается от anchor\n",
        "# результат должен быть побольше\n",
        "y_true = tf.constant([[1, 1], [1, 1], [2, 2], [0, 0]], dtype=tf.float32)\n",
        "print(multilabel_triplet_semihard_loss(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8d927b-9cde-446a-fe1e-110fa9dc6c8e",
        "id": "d-SI_ZoWcLyn"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}